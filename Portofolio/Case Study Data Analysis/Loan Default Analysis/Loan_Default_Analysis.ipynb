# Loan DefaultÂ Analysis
##Importing Libraries
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
import numpy as np
## Loading Data

Please download the dataset [here](https://drive.google.com/file/d/1Gcz2xehrld10NUD8_VIXfZXFvpc2OpG8/view?usp=sharing)

You can read about dataset description [here](https://github.com/saheninur/BFP_PACMANN/blob/e17c3b68f2554f6fc3a10a07c4542ccb8f8ad025/Portofolio/Case%20Study%20Data%20Analysis/Loan%20Default%C2%A0Analysis/README.md)
# Load dataset
data = pd.read_csv('financial_loan.csv')

# Display the first few rows
print(pd.DataFrame(data.head(10)).to_string(index=False))
# Check data types and missing values
print(data.info())
## Data Cleaning
# Drop rows with missing values
data = data.dropna()

# Check the dataset info after dropping missing values
data.info()
# Drop duplicates
data = data.drop_duplicates()

# Check the dataset info after dropping duplicates
data.info()
## Exploratory Data Analysis (EDA)
### Summary Statistics
Provides a quick overview of numerical variables to identify trends, outliers, and potential anomalies in the dataset.
# Summary statistics
print(data.describe())
### Correlation Matrix
Analyzing relationships between key numerical variables to identify patterns, particularly between loan amounts and other features such as income, debt-to-income ratio, and interest rates.

- annual_income dengan loan_amount: Korelasi antara pendapatan tahunan dan jumlah pinjaman yang diberikan.
- dti (Debt-to-Income ratio) dengan loan_amount: Korelasi antara rasio utang terhadap pendapatan dan jumlah pinjaman.
- installment dengan loan_amount: Korelasi antara cicilan bulanan dan jumlah pinjaman.
- int_rate dengan loan_amount: Korelasi antara tingkat bunga dan jumlah pinjaman.
- total_acc (total credit accounts) dengan loan_amount: Korelasi antara jumlah akun kredit dan jumlah pinjaman.
- total_payment dengan loan_amount: Korelasi antara total pembayaran yang dilakukan dan jumlah pinjaman.
# Select specific columns related to loan analysis
selected_columns = ['annual_income', 'dti', 'installment', 'int_rate', 'loan_amount', 'total_acc', 'total_payment']

# Subset the data with the selected columns
selected_data = data[selected_columns]

# Calculate the correlation matrix for the selected columns
correlation_matrix = selected_data.corr()

# Display the correlation matrix
print(correlation_matrix)
# Visualize the correlation matrix using a heatmap
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm')
plt.title('Correlation Matrix')
plt.show()
### Exploring Key Features
####Grade distribution
This analysis shows the number of loans by grade score to understand the distribution across risk categories.
# Count the number of loans in each grade
data['grade'].value_counts()
####Loan Status Distribution

Analyzing the proportion of loans that are fully paid versus defaulted helps understand the dataset's target variable distribution.
# Count the number of loans by loan status
data['loan_status'].value_counts()
####Loan Amount and Total Payment by Loan Status
Compare average loan amounts and total payments between defaulted and fully paid loans.
# Display unique values in loan_status
print(data['loan_status'].unique())
# Mengelompokkan Group by loan_status and calculate the mean loan_amount and total_payment
data.groupby('loan_status')[['loan_amount', 'total_payment']].mean()
# Boxplots for loan_amount and total_payment by loan_status
plt.figure(figsize=(12, 6))

# Boxplot for loan_amount
plt.subplot(1, 2, 1)
sns.boxplot(data=data, x='loan_status', y='loan_amount')
plt.title('Loan Amount per Loan Status')

# Boxplot for total_payment
plt.subplot(1, 2, 2)
sns.boxplot(data=data, x='loan_status', y='total_payment')
plt.title('Total Payment per Loan Status')

plt.tight_layout()
plt.show()

- For loan_amount: It looks like the "Current" status loans have slightly higher loan amounts on average compared to the "Charged Off" and "Fully Paid" categories, which is expected.
- For total_payment: It appears that "Charged Off" loans have a wider distribution of total payments, likely reflecting the variations in payment histories before the loan became charged off. "Fully Paid" loans have a more compact distribution, while "Current" loans again show a higher variation in payments.
####Scatter Plot: Annual Income vs. Loan Amount
Shows the relationship between annual income and loan amount, with color-coded loan status for additional insight.
# Scatter plot: Annual Income vs Loan amount
sns.scatterplot(data=data, x='annual_income', y='loan_amount', hue='loan_status', palette='cool')
plt.title('Annual Income vs Loan Amount')
plt.xlabel('Annual Income')
plt.ylabel('Loan Amount')
plt.legend(title='Default Status')
plt.show()
####Distribution Analysis: Loan Amount and Annual Income
Visualizing the distribution of loan amount and annual income (before and after log transformation) to check for skewness.
# Distribution of Loan Income
sns.histplot(data['loan_amount'], kde=True)
plt.title('Distribution of Loan Amount')
plt.show()
# Log-transform columns for better distribution analysis
data['log_annual_income'] = np.log1p(data['annual_income'])
data['log_loan_amount'] = np.log1p(data['loan_amount'])

# Subplot distribusi log-transform
fig, axes = plt.subplots(1, 2, figsize=(12, 5))

sns.histplot(data['log_annual_income'], kde=True, ax=axes[0], color='skyblue')
axes[0].set_title('Log Distribution of Annual Income')
axes[0].set_xlabel('Log Annual Income')

sns.histplot(data['log_loan_amount'], kde=True, ax=axes[1], color='orange')
axes[1].set_title('Log Distribution of Loan Amount')
axes[1].set_xlabel('Log Loan Amount')

plt.tight_layout()
plt.show()

###Feature Transformation for High-Risk Analysis
####Grade Mapping
Grades are mapped to numerical values to enable analysis of credit risk scores.
# Ensure all values in 'grade' are mapped correctly
print(data['grade'].unique())
data.info()
data['grade'] = data['grade'].astype(str)

# Map grades to numerical values
grade_mapping = {
    'A': 1,
    'B': 2,
    'C': 3,
    'D': 4,
    'E': 5,
    'F': 6,
    'G': 7
}

data['grade'] = data['grade'].map(grade_mapping)

# Verify the mean grade value after mapping
data['grade'].mean()
####Employee Length Cleanup
Clean the emp_length column to ensure numerical consistency.
# Clean the emp_length column by removing non-numeric characters
data['emp_length'] = data['emp_length'].replace({'years': '', 'year': '', r'\+': '', '<' : ''}, regex=True)

# Convert cleaned emp_length to numeric
data_cek = pd.to_numeric(data['emp_length'])
data_cek.mean()
####Summary Statistics for Key Features
Key statistics to highlight maximum, minimum, and average values for important columns.
print("Mean Loan Amount:", data['loan_amount'].mean())
print("Max Debt-to-Income Ratio:", data['dti'].max())
print("Mean Annual Income:", data['annual_income'].mean())
print("Min Annual Income:", data['annual_income'].min())
print("Max Installment:", data['installment'].max())
print("Max Interest Rate:", data['int_rate'].max())
# Machine Learning for Prediction: High-Risk Loan Classification(OPTIONAL)
In this section, we will apply machine learning to predict the likelihood of high-risk loans. We will build a Logistic Regression model to classify loans based on several features such as employment length, grade, loan amount, and others. The prediction target will be the high_risk label, which is based on criteria like the debt-to-income ratio, annual income, loan amount, and interest rate.
## Feature Engineering
# Clean emp_length column
data['emp_length'] = data['emp_length'].replace({'years': '', 'year': '', r'\+': '', '<' : ''}, regex=True)

# Create high_risk target based on business-specific criteria
data['high_risk'] = (
    (pd.to_numeric(data['emp_length'], errors='coerce') < 5) |  # Less than 5 years of employment
    (data['grade'] >= 4.0) |  # Grade D, E, F, G indicate higher risk
    (data['loan_amount'] > 150000) |  # Loans greater than 150k
    (data['dti'] > 5) |  # Debt-to-income ratio higher than 5
    (data['annual_income'] < 30000) |  # Annual income less than 30k
    (data['int_rate'] > 5) |  # Interest rate greater than 5%
    (data['installment'] > 1000)  # Monthly installment greater than 1k
).astype(int)

# Features and target selection
features = ['emp_length', 'grade', 'loan_amount', 'dti', 'annual_income', 'int_rate', 'installment']
target = 'high_risk'

X = data[features]
y = data[target]
# Display the cleaned data with high_risk column
print(pd.DataFrame(data.head(10)).to_string(index=False))
# Check the distribution of the target variable
print(data['high_risk'].value_counts())
## Model and Evaluatin
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
from sklearn.model_selection import cross_val_score

# Split the data into training and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Build and train the Logistic Regression model
model = LogisticRegression(random_state=42)
model.fit(X_train, y_train)

# Predict on the test data
y_pred = model.predict(X_test)

# Evaluate the model
print("Accuracy:", accuracy_score(y_test, y_pred))
print("Classification Report:\n", classification_report(y_test, y_pred))
print("Confusion Matrix:\n", confusion_matrix(y_test, y_pred))# Perform cross-validation
scores = cross_val_score(model, X, y, cv=5, scoring='accuracy')
print(f"Cross-validated accuracy: {scores.mean()}")
# Export Data
# Export the cleaned dataset to CSV
data.to_csv('cleaned_loan_data.csv', index=False)

# You can then download the file using the link generated
print("CSV file has been saved successfully!")
from sqlalchemy import create_engine

# Create a connection to an SQLite database (path is adjusted to avoid errors)
engine = create_engine('sqlite:///cleaned_loan_data.db')

# Export the DataFrame to the SQL database
data.to_sql('loan_data', con=engine, index=False, if_exists='replace')

# Print success message
print("Data has been successfully exported to SQL database!")
